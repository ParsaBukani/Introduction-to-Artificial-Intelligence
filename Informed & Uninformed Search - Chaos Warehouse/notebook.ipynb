{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsa KafshduziBukani\n",
    "This project develops solvers for a Sokoban-like game with portals. The goal is to move boxes to their specific goals using a player, dealing with walls and up to two portal pairs.\n",
    "\n",
    "We implemented four search algorithms: BFS, DFS, IDS, and A*. These find paths to solve the game efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import Game\n",
    "import time\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_map_files(directory):\n",
    "    pattern = re.compile(r'^map(\\d+)\\.txt$')\n",
    "    map_file_indices = []\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            map_file_indices.append(match.group(1))\n",
    "\n",
    "    return [int(idx) for idx in map_file_indices]\n",
    "\n",
    "def is_valid_input(map, indices, algorithm, solvers):\n",
    "    valid_input = True\n",
    "    if map not in indices:\n",
    "        print(f\"Map index out of range. Please choose within range {min(indices)} to {max(indices)}\")\n",
    "        valid_input = False\n",
    "    if algorithm not in solvers.keys():    \n",
    "        print(f\"{algorithm} is not a defined algorithm. Please choose from\", *[f\"{solver} ({i+1})  \" for i, solver in enumerate(solvers.keys())])\n",
    "        valid_input = False\n",
    "    return valid_input\n",
    "\n",
    "def load_map(map_index):  \n",
    "    file_name = \"map\" + str(map_index) + \".txt\"\n",
    "    with open('./assets/maps/' + file_name) as f:\n",
    "        game_map = f.read()\n",
    "    return game_map\n",
    "\n",
    "map_file_indices = extract_map_files(\"./assets/maps/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game State and Solver Classes\n",
    "\n",
    " State Class:\n",
    "\n",
    "The `State` class represents the current state of the game. It stores the positions of the player and boxes, along with the moves made so far. Each state has three instance variables:\n",
    "\n",
    "- **`player_pos`**: A tuple of two integers representing the player’s row and column position.  \n",
    "- **`boxes_pos`**: A tuple of tuples, where each inner tuple contains two integers for a box’s row and column position.  \n",
    "- **`solution_path`**: A string of move directions, initially empty, tracking the path taken.  \n",
    "\n",
    "  \n",
    "       \n",
    " GameSolver Class:\n",
    "\n",
    "The `GameSolver` class manages the game and generates possible moves. It simplifies how solvers interact with the game map. It has three main instance variables:\n",
    "\n",
    "- **`game`**: An instance of the `Game` class, holding the map and current game details.  \n",
    "- **`initial_state`**: A `State` object set at the start, storing the initial player and box positions.  \n",
    "- **`goal_positions`**: A tuple of tuples, where each inner tuple contains two integers for a goal’s row and column position.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Set, Dict\n",
    "\n",
    "class Direction(Enum):\n",
    "    UP = 'U'\n",
    "    DOWN = 'D'\n",
    "    LEFT = 'L'\n",
    "    RIGHT = 'R'\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class State:\n",
    "    player_pos: Tuple[int, int]\n",
    "    boxes_pos: Tuple[Tuple[int, int], ...]\n",
    "    solution_path: str = \"\"\n",
    "    \n",
    "    def get_player_pos(self) -> Tuple[int, int]:\n",
    "        return self.player_pos\n",
    "    \n",
    "    def get_boxes_pos(self) -> Tuple[Tuple[int, int], ...]:\n",
    "        return self.boxes_pos\n",
    "    \n",
    "    def get_solution_path(self) -> str:\n",
    "        return self.solution_path\n",
    "    \n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if not isinstance(other, State):\n",
    "            return False\n",
    "        return self.player_pos == other.player_pos and self.boxes_pos == other.boxes_pos\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.player_pos, self.boxes_pos))\n",
    "    \n",
    "    def __lt__(self, other: \"State\") -> bool:\n",
    "        return True \n",
    "\n",
    "class GameSolver:\n",
    "    def __init__(self, game: Game):\n",
    "        self.game = game\n",
    "        self.initial_state = self._build_initial_state()\n",
    "        self.goal_positions = tuple(tuple(goal) for goal in game.get_goal_locations())\n",
    "\n",
    "    def _build_initial_state(self) -> State:\n",
    "        return State(\n",
    "            player_pos=self.game.get_player_position(),\n",
    "            boxes_pos=tuple(tuple(box) for box in self.game.get_box_locations()),\n",
    "            solution_path=\"\"\n",
    "        )\n",
    "\n",
    "    def _apply_move_and_get_state(self, state: State, direction: str) -> State | None:\n",
    "        self.game.set_player_position(state.get_player_pos())\n",
    "        self.game.set_box_positions(list(state.get_boxes_pos()))\n",
    "        \n",
    "        if self.game.apply_move(direction):\n",
    "            return State(\n",
    "                player_pos=self.game.get_player_position(),\n",
    "                boxes_pos=tuple(tuple(box) for box in self.game.get_box_locations()),\n",
    "                solution_path=state.get_solution_path() + direction\n",
    "            )\n",
    "        return None\n",
    "\n",
    "    def get_next_states(self, state: State, visited: Set[State]) -> List[State]:\n",
    "        next_states = []\n",
    "        for direction in Direction:\n",
    "            new_state = self._apply_move_and_get_state(state, direction.value)\n",
    "            if new_state and new_state not in visited:\n",
    "                next_states.append(new_state)\n",
    "        return next_states\n",
    "\n",
    "    def get_next_dls_astar_states(self, state: State, depth: int, visited: Dict[State, int]) -> List[State]:\n",
    "        next_states = []\n",
    "        for direction in Direction:\n",
    "            new_state = self._apply_move_and_get_state(state, direction.value)\n",
    "            if new_state and (new_state not in visited or visited[new_state] > depth + 1):\n",
    "                next_states.append(new_state)\n",
    "        return next_states\n",
    "  \n",
    "    def is_goal_state(self, state: State) -> bool:\n",
    "        boxes = state.get_boxes_pos()\n",
    "        for i in range(len(self.goal_positions)):\n",
    "            if boxes[i] != self.goal_positions[i]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def get_initial_state(self) -> State:\n",
    "        return self.initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS Solver\n",
    "\n",
    "The `solver_bfs` function uses **Breadth-First Search (BFS)** to find a solution for the game. It explores all possible moves level by level to ensure the shortest path.\n",
    "\n",
    "Key parts:\n",
    "\n",
    "- **Queue**: Uses a `deque` to store states, adding new ones to the end and taking from the front.  \n",
    "- **Visited States**: A `set` tracks seen states to avoid revisiting them.  \n",
    "- **Next States**: Calls `GameSolver.get_next_states` to generate moves from the current state.  \n",
    "- **Goal Check**: Uses `GameSolver.is_goal_state` to stop when boxes reach their goal positions.  \n",
    "- **Return**: Outputs the solution path and the number of visited states.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def solver_bfs(game_map):\n",
    "    solver = GameSolver(Game(game_map))\n",
    "    if solver.is_goal_state(solver.get_initial_state()):\n",
    "        return \"\", 0\n",
    "    \n",
    "    queue = deque([solver.get_initial_state()])\n",
    "    visited_states = {solver.get_initial_state()}\n",
    "\n",
    "    while queue:\n",
    "        cur_state = queue.popleft()\n",
    "        for next_state in solver.get_next_states(cur_state, visited_states):\n",
    "            if solver.is_goal_state(next_state):\n",
    "                return next_state.get_solution_path(), len(visited_states)\n",
    "            queue.append(next_state)\n",
    "            visited_states.add(next_state)\n",
    "\n",
    "    return None, len(visited_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS Solver\n",
    "\n",
    "The `solver_dfs` function uses **Depth-First Search (DFS)** to find a solution for the game. It explores deep into one path before backtracking.\n",
    "\n",
    "Key parts:\n",
    "\n",
    "- **Stack**: Uses a `deque` as a stack, adding and removing states from the end.  \n",
    "- **Visited States**: A `set` tracks seen states to avoid revisiting them.  \n",
    "- **Next States**: Calls `GameSolver.get_next_states` to generate moves from the current state.  \n",
    "- **Goal Check**: Uses `GameSolver.is_goal_state` to stop when boxes reach their goal positions.  \n",
    "- **Return**: Outputs the solution path and the stack length (states in the current path).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def solver_dfs(game_map):\n",
    "    solver = GameSolver(Game(game_map))\n",
    "    goal_positions = solver.goal_positions \n",
    "    stack = deque()\n",
    "    visited_states = set()\n",
    "\n",
    "    if solver.is_goal_state(solver.get_initial_state()):\n",
    "        return \"\", 0\n",
    "    initial_state = solver.get_initial_state()\n",
    "    stack.append(initial_state)\n",
    "    visited_states.add(initial_state)\n",
    "\n",
    "    while stack:\n",
    "        cur_state = stack[-1]\n",
    "        next_States = solver.get_next_states(cur_state, visited_states)\n",
    "\n",
    "        if len(next_States) == 0:\n",
    "            stack.pop()\n",
    "\n",
    "        for next_state in next_States:\n",
    "            if solver.is_goal_state(next_state):\n",
    "                return next_state.get_solution_path(), len(stack)\n",
    "            \n",
    "            stack.append(next_state)\n",
    "            visited_states.add(next_state)\n",
    "\n",
    "    return None, len(visited_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDS Solver\n",
    "\n",
    "The `solver_ids` function uses **Iterative Deepening Search (IDS)** to find a solution. It repeatedly runs **Depth-Limited Search (DLS)** with increasing depth limits.\n",
    "\n",
    "Key parts:\n",
    "\n",
    "##### **Depth-Limited Search (DLS)**\n",
    "- **Stack**: Uses a `deque` to store states, popping from the end.  \n",
    "- **Visited States**: A `dict` tracks states and their depths to enforce the limit.  \n",
    "- **Next States**: Calls `GameSolver.get_next_dls_astar_states` to generate moves.  \n",
    "- **Return**: Outputs the solution path, `len(stack)`, and a status:  \n",
    "  - `1` → Solution found  \n",
    "  - `2` → No solution exists  \n",
    "  - `0` → Continue searching  \n",
    "\n",
    "##### **Iterative Deepening Loop**\n",
    "- **Loop**: Increases depth and calls DLS until a solution is found or no states remain.  \n",
    "- **Seen States**: Sums up `visited states` from each DLS run to track total states explored in the path to reaching the goal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLS(solver: GameSolver, limit, goal_positions, initial_state): \n",
    "    stack = deque()\n",
    "    visited_states = dict()\n",
    "\n",
    "    stack.append(initial_state)\n",
    "    visited_states[initial_state] = 0\n",
    "    is_without_solution = True\n",
    "\n",
    "    while stack:\n",
    "        cur_state = stack[-1]\n",
    "        depth = visited_states[cur_state]\n",
    "        next_States = solver.get_next_dls_astar_states(cur_state, depth, visited_states)\n",
    "\n",
    "        if len(next_States) == 0 or (depth >= limit):\n",
    "            if len(next_States) != 0:\n",
    "                is_without_solution = False\n",
    "            \n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        for next_state in next_States:\n",
    "            if solver.is_goal_state(next_state):\n",
    "                return next_state.get_solution_path(), len(stack), 1\n",
    "\n",
    "            stack.append(next_state)\n",
    "            visited_states[next_state] = depth + 1\n",
    "\n",
    "    return None, len(visited_states), (2 if is_without_solution else 0)\n",
    "\n",
    "\n",
    "def solver_ids(game_map):\n",
    "    HAS_SOLUTION = 1\n",
    "    NO_SOLUTION = 2\n",
    "\n",
    "    solver = GameSolver(Game(game_map))\n",
    "    goal_positions = solver.goal_positions\n",
    "\n",
    "    if solver.is_goal_state(solver.get_initial_state()):\n",
    "        return \"\", 0\n",
    "    initial_state = solver.get_initial_state()\n",
    "    \n",
    "    seen_states_sum = 0\n",
    "    depth = 0\n",
    "    while True:\n",
    "        solution_path, num_of_states, answer = DLS(solver, depth, goal_positions, initial_state)\n",
    "        seen_states_sum += num_of_states\n",
    "        if answer == HAS_SOLUTION:\n",
    "            return solution_path, seen_states_sum\n",
    "        elif answer == NO_SOLUTION:\n",
    "            break\n",
    "         \n",
    "        depth += 1\n",
    "    \n",
    "    return None, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic Functions\n",
    "\n",
    "Two heuristic functions for **A\\*** have been implemented to estimate the cost of solving the game and guide the search.\n",
    "\n",
    "#### **1. Manhattan Heuristic**\n",
    "\n",
    "This function calculates a basic cost using **Manhattan distances**:       \n",
    "        \n",
    "- **Box-to-Goal**: Sums the Manhattan distance (x and y differences) from each box to its goal.  \n",
    "- **Player-to-Box**: Finds the smallest Manhattan distance from the player to any box.  \n",
    "- **Total Cost**: Adds the box-to-goal sum and the minimum player-to-box distance.  \n",
    "\n",
    "*Notes*:  \n",
    "  - This heuristic **ignores portals and walls**, making it simple but less accurate.  \n",
    "  - Player's distance to all boxes does not matter, but the nearest box to it is important.  \n",
    "\n",
    "#### **2. Portal-Deadlock-Goal Heuristic**\n",
    "\n",
    "This function improves accuracy by considering **portals, walls, and goals**:\n",
    "\n",
    "- **Box-to-Goal**: Uses `get_minimum_distance_with_portals` to compute the minimum distance from each box to its goal.  \n",
    "- **Player-to-Box**: Finds the smallest distance from the player to any unsolved box.  \n",
    "- **Wall Penalty**: Adds `+2` to the cost for each box near a wall, avoiding deadlocks.  \n",
    "- **Goal Bonus**: Subtracts `-2` for each box already on its goal, rewarding progress.  \n",
    "- **Total Cost**: Combines box-to-goal cost, wall penalties, goal bonuses, and minimum player-to-box distance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_heuristic(state: State, goal_positions: Tuple[Tuple[int, int], ...], portals, game: Game) -> int:\n",
    "    total_distance = 0\n",
    "    boxes = state.get_boxes_pos()\n",
    "    player_x, player_y = state.get_player_pos()\n",
    "\n",
    "    min_player_to_box = float('inf')\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        box_x, box_y = boxes[i]\n",
    "        goal_x, goal_y = goal_positions[i]\n",
    "\n",
    "        box_to_goal_dist = abs(box_x - goal_x) + abs(box_y - goal_y)\n",
    "        total_distance += box_to_goal_dist\n",
    "\n",
    "        player_to_box_dist = abs(player_x - box_x) + abs(player_y - box_y)\n",
    "        min_player_to_box = min(min_player_to_box, player_to_box_dist)\n",
    "\n",
    "    return total_distance + min_player_to_box\n",
    "\n",
    "\n",
    "def get_minimum_distance_with_portals(start, end, portals):\n",
    "    \"\"\"\n",
    "    Computes the minimum Manhattan distance from 'start' to 'end',\n",
    "    considering direct paths and paths using up to two portal pairs.\n",
    "    \"\"\"\n",
    "    direct_distance = abs(start[0] - end[0]) + abs(start[1] - end[1])\n",
    "    min_distance = direct_distance\n",
    "\n",
    "    for p1_in, p1_out in portals:\n",
    "        dist_via_p1 = (abs(start[0] - p1_in[0]) + abs(start[1] - p1_in[1]) + \n",
    "                       abs(p1_out[0] - end[0]) + abs(p1_out[1] - end[1]))\n",
    "        \n",
    "        min_distance = min(min_distance, dist_via_p1)\n",
    "\n",
    "    if len(portals) >= 2:\n",
    "        p1_in, p1_out = portals[0]\n",
    "        p2_in, p2_out = portals[1]\n",
    "        \n",
    "        dist_p1_then_p2 = (abs(start[0] - p1_in[0]) + abs(start[1] - p1_in[1]) + \n",
    "                           abs(p1_out[0] - p2_in[0]) + abs(p1_out[1] - p2_in[1]) + \n",
    "                           abs(p2_out[0] - end[0]) + abs(p2_out[1] - end[1]))\n",
    "        \n",
    "        dist_p2_then_p1 = (abs(start[0] - p2_in[0]) + abs(start[1] - p2_in[1]) + \n",
    "                           abs(p2_out[0] - p1_in[0]) + abs(p2_out[1] - p1_in[1]) + \n",
    "                           abs(p1_out[0] - end[0]) + abs(p1_out[1] - end[1]))\n",
    "        \n",
    "        min_distance = min(min_distance, dist_p1_then_p2, dist_p2_then_p1)\n",
    "\n",
    "    return min_distance\n",
    "\n",
    "def portal_deadlock_goals_heuristic(state: State, goal_positions: Tuple[Tuple[int, int], ...], portals, game: Game) -> int:\n",
    "    boxes = state.get_boxes_pos()\n",
    "    player_pos = state.get_player_pos()\n",
    "    total_cost = 0\n",
    "    min_player_to_box = float('inf')\n",
    "    \n",
    "    for i, box in enumerate(boxes):\n",
    "        if box != goal_positions[i]: \n",
    "            player_to_box = get_minimum_distance_with_portals(player_pos, box, portals)\n",
    "            min_player_to_box = min(player_to_box, min_player_to_box)\n",
    "\n",
    "            box_to_goal = get_minimum_distance_with_portals(box, goal_positions[i], portals)\n",
    "            total_cost += box_to_goal\n",
    "\n",
    "            if any(\"W\" in game.get_elements_in_position((box[0] + dy, box[1] + dx))\n",
    "                   for dy, dx in [(1, 0), (-1, 0), (0, 1), (0, -1)]):\n",
    "                total_cost += 2\n",
    "        else: \n",
    "            total_cost -= 2\n",
    "    \n",
    "    return total_cost + min_player_to_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A* Solver\n",
    "\n",
    "Two versions of the solver_astar function have been implemented.\n",
    "\n",
    "#### **solver_astar:**\n",
    "\n",
    "This is a faster version of A* that prioritizes quick solutions.\n",
    "\n",
    "Key parts:\n",
    "- **Heap**: Uses a ```min_heap``` to prioritize states by cost plus weighted heuristic.\n",
    "- **Visited States**: A dict tracks states and their costs, skipping if a higher cost is revisited.\n",
    "- **Next States**: Calls ```GameSolver.get_next_dls_astar_states``` to generate moves.\n",
    "- **Goal Check**: Checks each new state with ```GameSolver.is_goal_state``` and returns immediately if a goal is found, ignoring lower-cost states in the heap.\n",
    "- **Return**: Gives the solution path and number of visited states.\n",
    "\n",
    "#### **solver_astar_optimal:**\n",
    "\n",
    "This version ensures the shortest path _(if the heuristic function is admissible)_ by selecting the best state.\n",
    "\n",
    "Key parts:\n",
    "- **Heap**: Uses a ```min_heap``` with the same priority logic.\n",
    "- **Visited States**: A dict tracks costs, skipping higher-cost revisits.\n",
    "- **Is Goal State**: A dict tracks which states are goals, precomputed for the initial state.\n",
    "- **Next States**: Calls ```GameSolver.get_next_dls_astar_states``` to generate moves.\n",
    "- **Goal Check**: Checks new states with ```GameSolver.is_goal_state```. If a goal is found, returns only if its cost is less than or equal to the heap’s top priority, ensuring the shortest path.\n",
    "- **Return**: Gives the solution path and number of visited states.\n",
    "\n",
    "**Differences**:\n",
    "- ```solver_astar``` is faster because it returns the first goal state it finds, even if a shorter path exists in the heap.\n",
    "- ```solver_astar_optimal``` guarantees the shortest path (with an admissible heuristic like ```portal_deadlock_goals_heuristic```) by only returning the goal state with the lowest cost, checked against the heap’s top priority.\n",
    "- The trade-off is that ```solver_astar_optimal``` may take longer due to waiting for the optimal state, while ```solver_astar``` sacrifices optimality for speed.  \n",
    "\n",
    "\n",
    "**Notes:**\n",
    "  *  In this project the **solver_astar** function is used for answering the questions.\n",
    "  *  The **solver_astar** function is optimal with ```weight <= 0.5``` for the given maps (Lower weight guarantees more optimality).\n",
    "  *  The datasets used for **BFS** and **A\\*** are different. BFS uses a queue while A* uses a priority queue. In general, queues are much faster than priority queues (eg. Dequeue() is O(1) vs O(log n)). so there might be unexpected timing differnces between the two.\n",
    "  *  It is also important to note that since the graph in this project is unweighted, **solver_bfs** may well outperform **solver_astar_optimal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def solver_astar(game_map, heuristic_func=portal_deadlock_goals_heuristic, weight=1):\n",
    "    solver = GameSolver(Game(game_map))\n",
    "    if solver.is_goal_state(solver.get_initial_state()):\n",
    "        return \"\", 0\n",
    "\n",
    "    goal_positions = solver.goal_positions\n",
    "    portals = solver.game.get_portal_locations()\n",
    "    visited_states = {}\n",
    "    min_heap = []\n",
    "\n",
    "    initial_state = solver.get_initial_state()\n",
    "    initial_cost = 0\n",
    "    initial_priority = initial_cost + weight * heuristic_func(initial_state, goal_positions, portals, solver.game)\n",
    "    \n",
    "    heapq.heappush(min_heap, (initial_priority, initial_cost, initial_state))\n",
    "    visited_states[initial_state] = initial_cost\n",
    "\n",
    "    while min_heap:\n",
    "        _, cur_cost, cur_state = heapq.heappop(min_heap)\n",
    "\n",
    "        if cur_cost > visited_states.get(cur_state, float('inf')):\n",
    "            continue\n",
    "\n",
    "        new_cost = cur_cost + 1\n",
    "        for next_state in solver.get_next_dls_astar_states(cur_state, cur_cost, visited_states):\n",
    "            if solver.is_goal_state(next_state):\n",
    "                return next_state.get_solution_path(), len(visited_states)\n",
    "\n",
    "            priority = new_cost + weight * heuristic_func(next_state, goal_positions, portals, solver.game)\n",
    "            heapq.heappush(min_heap, (priority, new_cost, next_state))\n",
    "            visited_states[next_state] = new_cost\n",
    "\n",
    "    return None, len(visited_states)\n",
    "\n",
    "\n",
    "def solver_astar_optimal(game_map, heuristic_func=portal_deadlock_goals_heuristic, weight=1):\n",
    "    solver = GameSolver(Game(game_map))\n",
    "    goal_positions = solver.goal_positions\n",
    "    portals = solver.game.get_portal_locations()\n",
    "    visited_states = {}\n",
    "    is_goal_state = {}\n",
    "    min_heap = []\n",
    "\n",
    "    initial_state = solver.get_initial_state()\n",
    "    initial_cost = 0\n",
    "    initial_priority = initial_cost + weight * heuristic_func(initial_state, goal_positions, portals, solver.game)\n",
    "    \n",
    "    heapq.heappush(min_heap, (initial_priority, initial_cost, initial_state))\n",
    "    visited_states[initial_state] = initial_cost\n",
    "    is_goal_state[initial_state] = solver.is_goal_state(initial_state)   \n",
    "\n",
    "    while min_heap:\n",
    "        _, cur_cost, cur_state = heapq.heappop(min_heap)\n",
    "\n",
    "        if cur_cost > visited_states.get(cur_state, float('inf')):\n",
    "            continue\n",
    "\n",
    "        if is_goal_state[cur_state]:\n",
    "            return cur_state.get_solution_path(), len(visited_states)\n",
    "\n",
    "        new_cost = cur_cost + 1\n",
    "        for next_state in solver.get_next_dls_astar_states(cur_state, cur_cost, visited_states):\n",
    "            priority = new_cost + weight * heuristic_func(next_state, goal_positions, portals, solver.game)\n",
    "            \n",
    "            heapq.heappush(min_heap, (priority, new_cost, next_state))\n",
    "\n",
    "            if solver.is_goal_state(next_state):\n",
    "                if priority <= min_heap[0][0]:\n",
    "                    return next_state.get_solution_path(), len(visited_states)\n",
    "                is_goal_state[next_state] = True\n",
    "            else:\n",
    "                is_goal_state[next_state] = False\n",
    "                \n",
    "            visited_states[next_state] = new_cost\n",
    "\n",
    "    return None, len(visited_states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVERS = {\n",
    "    \"BFS\": solver_bfs,\n",
    "    \"DFS\": solver_dfs,\n",
    "    \"IDS\": solver_ids,\n",
    "    \"A*\": solver_astar,\n",
    "    # \"A*_optimal\": solver_astar_optimal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(map, method, heuristic = portal_deadlock_goals_heuristic, weight=1):  \n",
    "    \n",
    "    if not is_valid_input(map, map_file_indices, method, SOLVERS):\n",
    "        return\n",
    "    \n",
    "    file_name = \"map\" + str(map) + \".txt\"\n",
    "    with open('./assets/maps/' + file_name) as f:\n",
    "        game_map = f.read()\n",
    "    \n",
    "    if method == \"A*\":\n",
    "        start_time = time.time()\n",
    "        moves, numof_visited_states = SOLVERS[method](game_map, heuristic, weight)\n",
    "        end_time = time.time()\n",
    "        if weight == 1:\n",
    "            print(f\"{method} took {round(end_time - start_time, 2)} seconds on map {map} and visited {numof_visited_states} states.\")\n",
    "        else:\n",
    "            print(f\"{\"weighted_\" + method} took {round(end_time - start_time, 2)} seconds on map {map} and visited {numof_visited_states} states.\")\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        moves, numof_visited_states = SOLVERS[method](game_map)\n",
    "        end_time = time.time()\n",
    "        print(f\"{method} took {round(end_time - start_time, 2)} seconds on map {map} and visited {numof_visited_states} states.\")\n",
    "    \n",
    "    if moves is None:\n",
    "        print(\"No Solution Found!\")\n",
    "    else:\n",
    "        print(f\"{len(moves)} moves were used: {moves}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_all():\n",
    "    for map in range(min(map_file_indices), max(map_file_indices) + 1):\n",
    "        for method in SOLVERS.keys():\n",
    "            solve(map, method)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "#### **1. What can be considered as the definition of a state in this problem? The most obvious definition for it is the warehouse map at each moment. What is the problem with that definition? How can it be improved?**\n",
    "\n",
    "\n",
    "A state in this problem can be considered as the configuration that determines the game’s progress at any point. One definition would be the entire warehouse map at each moment, including all details. The problem with this is that fixed elements like goals, walls, and portals don’t change and would waste memory if stored for every state. Instead, the definition can be improved by focusing only on the variable elements: the player’s position and the boxes’ positions, which are the key factors that change and affect the solution, as implemented in the State class.  \n",
    "\n",
    "\n",
    "#### **2. Based on the definition you have considered for the state, how would you define the actions?**\n",
    "\n",
    "Given the state definition as the player’s position and the boxes’ positions, an action is defined as a move that changes the state by updating these positions. Specifically, an action is one of the four possible moves the player can make: moving up, down, left, or right, as defined in the Direction enum.\n",
    "  \n",
    "    \n",
    "#### **3. Explain in detail how to model the problem, including the definition of actions, state, goal state, initial state, etc.**\n",
    "\n",
    "To represent this game as a searchable problem (e.g., for AI algorithms like BFS, DFS, or A*), we need to define its key components: the state, actions, initial state, and goal state. Below, I’ll explain each in detail.\n",
    "\n",
    "### State\n",
    "A state describes the current configuration of the game at any point. It includes only the dynamic elements that change as the player moves:\n",
    "\n",
    "- **Player’s Position**: Represented as a tuple (row, column) indicating where the player is on the grid.\n",
    "- **Boxes’ Positions**: A tuple of (row, column) tuples, one for each box, tracking their locations.\n",
    "\n",
    "Static elements like walls (impassable barriers), portals (teleportation points), and goal positions (where boxes need to end up) are not part of the state as explained previously.\n",
    "\n",
    "### Actions\n",
    "The player can take one of four actions at each step: move up, down, left, or right. However, the outcome of an action depends on the game’s rules:\n",
    "\n",
    "- **Basic Movement**: If the adjacent cell in the chosen direction is empty or a portal, the player moves there.\n",
    "    - If it’s a portal, the player teleports to the corresponding exit portal’s position.\n",
    "- **Pushing a Box**: If the adjacent cell contains a box, the player can push it, but only if the cell beyond the box (in the same direction) is empty or a portal.\n",
    "    - If the box is pushed into a portal, it teleports to the linked portal’s exit, and the player moves into the box’s original position.\n",
    "\n",
    "### Initial State\n",
    "The initial state is the starting point of the game, as provided by the game map. It specifies:\n",
    "\n",
    "- The player’s starting position.\n",
    "- The starting positions of all boxes.\n",
    "\n",
    "### Goal State\n",
    "The goal state is the desired end configuration:\n",
    "\n",
    "- All boxes must be on their corresponding goal positions (specific (row, column) locations defined in the game map).\n",
    "\n",
    "> ### Putting It Together\n",
    "With these components, we can model the game as a state-space search problem:\n",
    "\n",
    "1. Start at the initial state.\n",
    "2. Use the actions to generate possible next states (e.g., moving the player, pushing boxes, handling portals).\n",
    "3. Check each state against the goal state to see if the puzzle is solved.\n",
    "\n",
    "Algorithms like BFS (breadth-first search), DFS (depth-first search), or A* (with a heuristic) can explore this space to find a sequence of moves from the initial state to the goal state.\n",
    "\n",
    "\n",
    "#### **4. How can this problem be improved and the search space optimized? In search algorithms for this problem, should we expand all possible states that we can move to in the next step? What are the consequences of doing so? Explain what actions and considerations can be taken to improve this problem.**\n",
    "\n",
    "### Optimizing the Search Space\n",
    "\n",
    "The implementation enhances efficiency through several strategies:\n",
    "\n",
    "- **Visited States Tracking**: A set is utilized to track states that have already been encountered, preventing redundant exploration and keeping the search space streamlined.\n",
    "- **Early Goal Checking**: Each newly generated state is immediately evaluated to determine if it represents a goal. This avoids adding unnecessary states to the queue or stack.\n",
    "\n",
    "\n",
    "Expanding every possible state is not practical for the following reasons:\n",
    "\n",
    "- It increases memory consumption by including duplicate states.\n",
    "- It delays the search process, especially in uninformed strategies like breadth-first search (BFS), where efficiency depends on minimizing unnecessary expansions.\n",
    "\n",
    "Evaluating whether a state is a goal immediately after its generation accelerates the search due to these factors:\n",
    "\n",
    "- It reduces memory usage by avoiding the storage of states that do not contribute to the solution.\n",
    "- In methods such as depth-first search (DFS) or A*, this technique can yield faster results if a goal state is encountered early in the exploration.\n",
    "\n",
    "These optimizations contribute to a search process that is both faster and more memory-efficient.\n",
    "\n",
    "\n",
    "#### **5. Explain each of the implemented algorithms, highlighting the differences and advantages of each compared to the others. Mention which algorithms produce an optimal solution.**\n",
    "\n",
    "- **BFS (Breadth-First Search)**: This algorithm explores all possible states level by level, starting from the initial state. It checks every move one step away, then two steps, and so on. Because of this, BFS always finds the shortest path to the goal, making it **optimal**. Its advantage is this guarantee of optimality, but it uses a lot of memory since it stores all states at each level.\n",
    "\n",
    "- **DFS (Depth-First Search)**: DFS goes deep into one path until it hits a dead end, then backtracks to try another path. It uses less memory than BFS because it only tracks the current path. However, it’s **not optimal**. It might find a long path instead of the shortest one. Its advantage is simplicity and low memory use.\n",
    "\n",
    "- **IDS (Iterative Deepening Search)**: IDS runs DFS multiple times, starting with a small depth limit (here 0) and increasing it until a solution is found. It combines DFS’s low memory use with BFS’s guarantee of the shortest path, making it **optimal**. Its advantage is balancing memory efficiency and optimality.\n",
    "\n",
    "- **A\\* Search**: Uses a heuristic to prioritize paths that seem closer to the goal. It’s faster than BFS or IDS in many cases and is **optimal** if the heuristic is admissible. Its advantage is efficiency guided by smart guesses but A bad heuristic can make A* inefficient.\n",
    "\n",
    "**Differences and Advantages**:\n",
    "- BFS is memory-heavy but optimal; DFS is memory-light but not optimal.\n",
    "- IDS is a middle ground, optimal like BFS with less memory like DFS.\n",
    "- A* is faster and optimal, beating others with a good heuristic but it stores all explored nodes, making it memory-intensive for large graphs.\n",
    "\n",
    "\n",
    "> Problem with DFS and Why It’s Still Used:\n",
    "  It can miss the shortest path and get stuck exploring deep, useless paths.\n",
    "  But it uses little memory and can find a solution fast if the goal isn’t too deep, plus it’s easy to implement.\n",
    "\n",
    "\n",
    "> How IDS Combines DFS and BFS\n",
    "  IDS uses DFS’s deep exploration but repeats it with growing depth limits until the solution is found.\n",
    "  It tackles BFS’s high memory use while keeping the shortest-path guarantee, blending DFS’s efficiency with BFS’s optimality.\n",
    "\n",
    "\n",
    "#### **6 & 9. Implement the mentioned algorithms and justify your answers to question 5 with your implementations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS took 0.0 seconds on map 1 and visited 43 states.\n",
      "7 moves were used: UDDULRR\n",
      "DFS took 0.0 seconds on map 1 and visited 13 states.\n",
      "7 moves were used: RLLRDUU\n",
      "IDS took 0.0 seconds on map 1 and visited 158 states.\n",
      "7 moves were used: RLLRDUU\n",
      "A* took 0.0 seconds on map 1 and visited 22 states.\n",
      "7 moves were used: DULRUDR\n",
      "weighted_A* took 0.0 seconds on map 1 and visited 14 states.\n",
      "7 moves were used: RLLRDUU\n",
      "BFS took 0.0 seconds on map 2 and visited 20 states.\n",
      "6 moves were used: LUDDUL\n",
      "DFS took 0.0 seconds on map 2 and visited 9 states.\n",
      "6 moves were used: LLRDUU\n",
      "IDS took 0.0 seconds on map 2 and visited 62 states.\n",
      "6 moves were used: LLRDUU\n",
      "A* took 0.0 seconds on map 2 and visited 14 states.\n",
      "6 moves were used: LUDDUL\n",
      "weighted_A* took 0.0 seconds on map 2 and visited 10 states.\n",
      "6 moves were used: LLRDUU\n",
      "BFS took 0.0 seconds on map 3 and visited 121 states.\n",
      "13 moves were used: ULDDUUUURDDDD\n",
      "DFS took 0.0 seconds on map 3 and visited 19 states.\n",
      "13 moves were used: ULDDUUUURDDDD\n",
      "IDS took 0.01 seconds on map 3 and visited 558 states.\n",
      "13 moves were used: ULDDUUUURDDDD\n",
      "A* took 0.01 seconds on map 3 and visited 58 states.\n",
      "14 moves were used: ULUURDDDDUULDD\n",
      "weighted_A* took 0.0 seconds on map 3 and visited 30 states.\n",
      "13 moves were used: ULDDUUUURDDDD\n",
      "BFS took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "DFS took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "IDS took 0.0 seconds on map 4 and visited 0 states.\n",
      "No Solution Found!\n",
      "A* took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "weighted_A* took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "BFS took 0.1 seconds on map 5 and visited 6327 states.\n",
      "15 moves were used: ULDDRDLLLUUURUL\n",
      "DFS took 0.24 seconds on map 5 and visited 359 states.\n",
      "195 moves were used: LRDDLLLLUUURRDRRDDLLLLUURRLLDDRRRRUULDLRRUULLLLDDDRURRRUULLDRRDDLLLLUURRLLDDRRRRUULDLRRUULLDDRRUULLLLDDRRLLUURRRRDDLDLRRUULLLDRLLUURRRRDDDLURULRDDLLLRRRUULLRRDDLLLULURRLLUURRRRDDDLURULRDDLLUURULL\n",
      "IDS took 1.41 seconds on map 5 and visited 19744 states.\n",
      "15 moves were used: LULDLRDRDLLULUU\n",
      "A* took 0.02 seconds on map 5 and visited 584 states.\n",
      "15 moves were used: ULDDRDLLLUUURUL\n",
      "weighted_A* took 0.0 seconds on map 5 and visited 121 states.\n",
      "17 moves were used: LULDRDLLULDRUURUL\n",
      "BFS took 0.42 seconds on map 6 and visited 17806 states.\n",
      "34 moves were used: UUUUURRRLLLLLLLDDDDDDDDDRDLRRRRRRR\n",
      "A* took 0.04 seconds on map 6 and visited 1039 states.\n",
      "34 moves were used: DDDDDRRRLLLLLLLUUUUUUUUURULRRRRRRR\n",
      "weighted_A* took 0.01 seconds on map 6 and visited 177 states.\n",
      "34 moves were used: RRDDDDDRLLLLLLLUUUUUUUUURULRRRRRRR\n",
      "BFS took 17.58 seconds on map 7 and visited 644753 states.\n",
      "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLUUDR\n",
      "A* took 0.27 seconds on map 7 and visited 4982 states.\n",
      "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLUUDR\n",
      "weighted_A* took 0.06 seconds on map 7 and visited 1312 states.\n",
      "38 moves were used: RURRDLLLRRRDDDLDRUUUULLDRDRDDLLDLLURLU\n",
      "BFS took 0.12 seconds on map 8 and visited 7418 states.\n",
      "14 moves were used: UURDLDRRDRURDR\n",
      "IDS took 1.66 seconds on map 8 and visited 20082 states.\n",
      "14 moves were used: UURDLDRRDRURDR\n",
      "A* took 0.02 seconds on map 8 and visited 397 states.\n",
      "17 moves were used: URURDDLDRRRRURDDR\n",
      "weighted_A* took 0.0 seconds on map 8 and visited 81 states.\n",
      "19 moves were used: URRRRRRRRRRRRRURDDR\n",
      "weighted_A* took 0.42 seconds on map 9 and visited 9999 states.\n",
      "59 moves were used: RURRRLDDLULURRURDRDRDLDLURUUURDRDLLULLUUULLULURRURDDDDDDLDR\n",
      "BFS took 5.09 seconds on map 10 and visited 241502 states.\n",
      "46 moves were used: RRRRRDRULURULLLULDRUUULDRDLDRRDRULURURDDRDLLLL\n",
      "A* took 0.84 seconds on map 10 and visited 23089 states.\n",
      "46 moves were used: RRRRRDRULURULLLULLDRUULDRDLDRRDRULURURDDRDLLLL\n",
      "weighted_A* took 0.07 seconds on map 10 and visited 1718 states.\n",
      "52 moves were used: RRRRRDRURULULLUURDLDRRURRDLLLDDLLURRDRULURURDDRDLLLL\n"
     ]
    }
   ],
   "source": [
    "for map in range(min(map_file_indices), max(map_file_indices) + 1):\n",
    "    for method in SOLVERS.keys():\n",
    "        if method == \"BFS\" and map == 9:\n",
    "            continue\n",
    "        if method == \"DFS\":\n",
    "            if map in [6, 7 ,8, 9 ,10]:\n",
    "                continue\n",
    "        if method == \"IDS\":\n",
    "            if map in [6, 7, 9, 10]:\n",
    "                continue\n",
    "        if method == \"A*\":\n",
    "            if map == 9:\n",
    "                solve(map, method, portal_deadlock_goals_heuristic, 2.5)\n",
    "            else:\n",
    "                solve(map, method, portal_deadlock_goals_heuristic, 1)\n",
    "                solve(map, method, portal_deadlock_goals_heuristic, 2.5)\n",
    "        else:\n",
    "            solve(map, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Performance and Justification of Algorithms**\n",
    "\n",
    "1. **BFS (Breadth-First Search)**  \n",
    "   - **Finds optimal solutions** since it explores states level by level.  \n",
    "   - **High memory usage**, as it stores all visited states at each level.  \n",
    "   - **Slow for large maps** (e.g., Map 7 took 14.82s and visited 644,753 states).  \n",
    "\n",
    "2. **DFS (Depth-First Search)**  \n",
    "   - **Not optimal**, as it explores deep paths before checking shorter alternatives.  \n",
    "   - **Low memory usage**, but sometimes finds unnecessarily long solutions.  \n",
    "   - **Fast but inconsistent**, depending on the structure of the search space.  \n",
    "\n",
    "3. **IDS (Iterative Deepening Search)**  \n",
    "   - **Optimal like BFS** but **more memory-efficient**.  \n",
    "   - **Slow due to repeated DFS calls** (e.g., 1.46s for Map 5 vs. 0.1s for BFS).  \n",
    "   - Works well for small maps but inefficient for larger ones.  \n",
    "\n",
    "4. **A\\* Search**  \n",
    "   - **Optimal if the heuristic is admissible**.  \n",
    "   - **Faster than BFS** due to heuristic guidance (e.g., Map 7 took 0.3s vs. BFS's 14.82s).  \n",
    "   - **Memory-intensive** but effective for practical use.  \n",
    "\n",
    "5. **Weighted A\\***  \n",
    "   - **Not always optimal**, as it sacrifices correctness for speed.  \n",
    "   - **Significantly faster than A\\*** (e.g., Map 10 took 0.06s vs. 0.94s for A\\*).  \n",
    "   - **Useful for large-scale problems** where an approximate solution is acceptable.  \n",
    "\n",
    "### **Conclusion**  \n",
    "- **BFS and IDS guarantee optimality** but are impractical for large maps due to high memory usage.  \n",
    "- **DFS is memory-efficient but unreliable for optimal solutions**.  \n",
    "- **A\\* is the best balance of efficiency and optimality**.  \n",
    "- **Weighted A\\* is the fastest** but does not always find the shortest solution.  \n",
    "\n",
    "For real-world applications, **A\\*** is often the best choice due to its speed and optimality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Explain the heuristics introduced in the informed search section and analyze them in terms of admissibility and consistency.** \n",
    "\n",
    "In the informed search section, we introduced two heuristic functions for guiding the A* algorithm: **Manhattan Heuristic** and **Portal Deadlock Goals Heuristic**. Below, we analyze their admissibility and consistency.  \n",
    "\n",
    "##### **1. Manhattan Heuristic**  \n",
    "\n",
    "The **Manhattan heuristic** calculates the sum of Manhattan distances from each box to its corresponding goal, plus the minimum Manhattan distance from the player to any box.  \n",
    "\n",
    "- **Not admissible**: This heuristic overestimates the actual cost when portals are present. Since portals can significantly reduce the path length, the Manhattan distance (which ignores them) may assign a cost higher than the optimal path cost.  \n",
    "- **Not necessarily consistent**: If a state transition occurs via a portal, the estimated cost difference between states may not always match the true step cost, violating consistency.  \n",
    "\n",
    "##### **2. Portal Deadlock Goals Heuristic**  \n",
    "\n",
    "This heuristic improves upon the Manhattan heuristic by incorporating **portals, walls, and goal positions**. It calculates the shortest portal-adjusted distance from each box to its goal and considers player movement. Additionally, it penalizes boxes near walls (to prevent deadlocks) and rewards boxes already placed on goals.  \n",
    "\n",
    "- **Admissible**: This heuristic never overestimates the true cost because it considers all possible paths, including those using portals, ensuring the estimated cost does not exceed the optimal solution cost.  \n",
    "- **Likely consistent**: Since each state transition cost is properly reflected in the heuristic, and heuristic values decrease as boxes approach goals, it tends to satisfy consistency.   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8. Run the algorithm using all the heuristics you introduced and compare their results with each other:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhattan_heuristic:\n",
      "A* took 0.0 seconds on map 1 and visited 43 states.\n",
      "7 moves were used: DURLUDL\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.0 seconds on map 1 and visited 22 states.\n",
      "7 moves were used: DULRUDR\n",
      "manhattan_heuristic:\n",
      "A* took 0.0 seconds on map 2 and visited 20 states.\n",
      "6 moves were used: LDUUDL\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.0 seconds on map 2 and visited 14 states.\n",
      "6 moves were used: LUDDUL\n",
      "manhattan_heuristic:\n",
      "A* took 0.0 seconds on map 3 and visited 93 states.\n",
      "14 moves were used: ULUURDDDDUULDD\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.0 seconds on map 3 and visited 58 states.\n",
      "14 moves were used: ULUURDDDDUULDD\n",
      "manhattan_heuristic:\n",
      "A* took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.0 seconds on map 4 and visited 2 states.\n",
      "No Solution Found!\n",
      "manhattan_heuristic:\n",
      "A* took 0.03 seconds on map 5 and visited 1015 states.\n",
      "15 moves were used: LULDLRDRDLLULUU\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.02 seconds on map 5 and visited 584 states.\n",
      "15 moves were used: ULDDRDLLLUUURUL\n",
      "manhattan_heuristic:\n",
      "A* took 0.15 seconds on map 6 and visited 6024 states.\n",
      "34 moves were used: UUUUURRRLLLLLLLDDDDDDDDDRDLRRRRRRR\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.03 seconds on map 6 and visited 1039 states.\n",
      "34 moves were used: DDDDDRRRLLLLLLLUUUUUUUUURULRRRRRRR\n",
      "manhattan_heuristic:\n",
      "A* took 2.76 seconds on map 7 and visited 59233 states.\n",
      "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLUUDR\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.25 seconds on map 7 and visited 4982 states.\n",
      "34 moves were used: RURRDDDDLDRUUUULLLRDRDRDDLLDLLUUDR\n",
      "manhattan_heuristic:\n",
      "A* took 0.02 seconds on map 8 and visited 314 states.\n",
      "19 moves were used: URRRRRRRRRRRRRURDDR\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.0 seconds on map 8 and visited 397 states.\n",
      "17 moves were used: URURDDLDRRRRURDDR\n",
      "weighted_A* took 0.45 seconds on map 9 and visited 9999 states.\n",
      "59 moves were used: RURRRLDDLULURRURDRDRDLDLURUUURDRDLLULLUUULLULURRURDDDDDDLDR\n",
      "manhattan_heuristic:\n",
      "A* took 1.25 seconds on map 10 and visited 51816 states.\n",
      "46 moves were used: RRRRRDRULURULLLULDRUUULDRDLDRRDRULURURDDRDLLLL\n",
      "portal_deadlock_goals_heuristic:\n",
      "A* took 0.91 seconds on map 10 and visited 23089 states.\n",
      "46 moves were used: RRRRRDRULURULLLULLDRUULDRDLDRRDRULURURDDRDLLLL\n"
     ]
    }
   ],
   "source": [
    "for map in range(min(map_file_indices), max(map_file_indices) + 1):\n",
    "    if map == 9:\n",
    "        solve(map, \"A*\", portal_deadlock_goals_heuristic, 2.5)\n",
    "    else:\n",
    "        print(\"manhattan_heuristic:\")\n",
    "        solve(map, \"A*\", manhattan_heuristic, 1) \n",
    "        print(\"portal_deadlock_goals_heuristic:\")\n",
    "        solve(map, \"A*\", portal_deadlock_goals_heuristic, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
